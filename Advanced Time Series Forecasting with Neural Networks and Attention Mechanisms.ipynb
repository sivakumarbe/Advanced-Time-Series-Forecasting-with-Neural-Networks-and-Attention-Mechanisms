{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e392ab6-9f81-4875-9239-ee9611e1751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Attention-LSTM Time Series Forecasting Pipeline\n",
    "\n",
    "Single-file, production-quality Python implementation for:\n",
    "- Data loading (statsmodels macrodata) as a multivariate time series\n",
    "- Preprocessing: imputation, scaling, feature engineering\n",
    "- Model: LSTM with a Self-Attention mechanism (PyTorch)\n",
    "- Evaluation: MAE, RMSE (Fixed for new Scikit-Learn versions)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "from typing import Tuple, Dict, Any, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optuna is optional for this run, but we keep imports if you want to enable tuning later\n",
    "try:\n",
    "    import optuna\n",
    "    from optuna.trial import Trial\n",
    "    OPTUNA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "\n",
    "# Prophet is optional\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    PROPHET_AVAILABLE = True\n",
    "except Exception:\n",
    "    PROPHET_AVAILABLE = False\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility utilities\n",
    "# -----------------------------\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    \"\"\"Set random seed for reproducibility across numpy, random and torch.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -----------------------------\n",
    "# Data pipeline\n",
    "# -----------------------------\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "def load_macrodata() -> pd.DataFrame:\n",
    "    \"\"\"Load the 'macrodata' dataset from statsmodels.\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    data = sm.datasets.macrodata.load_pandas().data\n",
    "    # FIXED: Changed 'Q' to 'QE' to avoid FutureWarning in newer Pandas\n",
    "    dates = pd.date_range(start='1959-01-01', periods=len(data), freq='QE')\n",
    "    df = data.copy()\n",
    "    df.index = dates\n",
    "    \n",
    "    # Select a subset of useful signals\n",
    "    df = df[['realgdp', 'realcons', 'realinv', 'cpi', 'unemp']]\n",
    "    df.columns = ['gdp', 'cons', 'inv', 'cpi', 'unemp']\n",
    "    \n",
    "    # forward-fill missing and drop any remaining\n",
    "    df = df.ffill().bfill()\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_features(df: pd.DataFrame, lags: List[int] = [1,2,3,4], rolling_windows: List[int] = [4,8]) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    out = df.copy()\n",
    "    for col in df.columns:\n",
    "        for lag in lags:\n",
    "            out[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
    "        for rw in rolling_windows:\n",
    "            out[f'{col}_rmean{rw}'] = df[col].rolling(rw, min_periods=1).mean().shift(1)\n",
    "            out[f'{col}_rstd{rw}'] = df[col].rolling(rw, min_periods=1).std().shift(1).fillna(0.0)\n",
    "\n",
    "    # time features\n",
    "    out['quarter'] = out.index.quarter\n",
    "    out['year'] = out.index.year\n",
    "\n",
    "    # drop rows with any NaNs resulting from shifts\n",
    "    out = out.dropna()\n",
    "    feature_cols = [c for c in out.columns if c != 'gdp']  # we'll forecast 'gdp'\n",
    "    return out, feature_cols\n",
    "\n",
    "\n",
    "def scale_features(train: pd.DataFrame, valid: pd.DataFrame, test: pd.DataFrame, feature_cols: List[str]):\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(train[feature_cols])\n",
    "    X_valid = scaler.transform(valid[feature_cols])\n",
    "    X_test = scaler.transform(test[feature_cols])\n",
    "\n",
    "    y_train = train['gdp'].values.reshape(-1,1)\n",
    "    y_valid = valid['gdp'].values.reshape(-1,1)\n",
    "    y_test = test['gdp'].values.reshape(-1,1)\n",
    "\n",
    "    return (X_train, X_valid, X_test, y_train, y_valid, y_test, scaler)\n",
    "\n",
    "\n",
    "def create_sequences(X: np.ndarray, y: np.ndarray, seq_len: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_len):\n",
    "        Xs.append(X[i:i+seq_len])\n",
    "        ys.append(y[i+seq_len])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# -----------------------------\n",
    "# Model: LSTM with attention\n",
    "# -----------------------------\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        self.scale = 1.0 / math.sqrt(hidden_dim)\n",
    "\n",
    "    def forward(self, H: torch.Tensor) -> torch.Tensor:\n",
    "        # H: (batch, seq_len, hidden)\n",
    "        q = H.mean(dim=1, keepdim=True)  # (batch,1,hidden)\n",
    "        k = H  # (batch, seq, hidden)\n",
    "        scores = torch.matmul(q, k.transpose(1,2)) * self.scale  # (batch,1,seq)\n",
    "        weights = torch.softmax(scores, dim=-1)  # (batch,1,seq)\n",
    "        context = torch.matmul(weights, k).squeeze(1)  # (batch,hidden)\n",
    "        return context\n",
    "\n",
    "\n",
    "class AttentionLSTM(nn.Module):\n",
    "    def __init__(self, n_features: int, hidden_dim: int = 64, num_layers: int = 1, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers>1 else 0.0)\n",
    "        self.attn = SelfAttention(hidden_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim//2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # out: (batch, seq, hidden)\n",
    "        context = self.attn(out)  # (batch, hidden)\n",
    "        out = self.fc(context).squeeze(-1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class StandardLSTM(nn.Module):\n",
    "    def __init__(self, n_features: int, hidden_dim: int = 64, num_layers: int = 1, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers>1 else 0.0)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        last = hn[-1]\n",
    "        out = self.fc(last).squeeze(-1)\n",
    "        return out\n",
    "\n",
    "# -----------------------------\n",
    "# Training and evaluation utilities\n",
    "# -----------------------------\n",
    "\n",
    "def train_one_epoch(model: nn.Module, loader: DataLoader, opt: torch.optim.Optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for Xb, yb in loader:\n",
    "        Xb = Xb.to(device)\n",
    "        yb = yb.to(device).squeeze(-1)\n",
    "        opt.zero_grad()\n",
    "        preds = model(Xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * Xb.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    preds_list, trues_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in loader:\n",
    "            Xb = Xb.to(device)\n",
    "            preds = model(Xb).detach().cpu().numpy()\n",
    "            preds_list.append(preds)\n",
    "            trues_list.append(yb.numpy().squeeze(-1))\n",
    "    y_pred = np.concatenate(preds_list)\n",
    "    y_true = np.concatenate(trues_list)\n",
    "    return y_true, y_pred\n",
    "\n",
    "\n",
    "def fit_model(model: nn.Module, train_loader: DataLoader, valid_loader: DataLoader, cfg: Dict[str, Any], device) -> Dict[str, Any]:\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=cfg.get('lr', 1e-3), weight_decay=cfg.get('weight_decay', 0.0))\n",
    "    criterion = nn.MSELoss()\n",
    "    best_val = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(cfg.get('epochs', 50)):\n",
    "        tr_loss = train_one_epoch(model, train_loader, opt, criterion, device)\n",
    "        yv, yp = evaluate(model, valid_loader, device)\n",
    "        val_loss = ((yv - yp) ** 2).mean()\n",
    "        history['train_loss'].append(tr_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "    \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return {'model': model, 'history': history, 'best_val': best_val}\n",
    "\n",
    "# -----------------------------\n",
    "# Backtesting utilities\n",
    "# -----------------------------\n",
    "\n",
    "def rolling_backtest(full_df: pd.DataFrame, feature_cols: List[str], seq_len: int, config: Dict[str, Any], n_folds: int = 3) -> Dict[str, Any]:\n",
    "    results = {'folds': []}\n",
    "    N = len(full_df)\n",
    "    fold_size = int(N * 0.12)\n",
    "    \n",
    "    for fold in range(n_folds):\n",
    "        print(f\"  > Processing Fold {fold+1}/{n_folds}...\")\n",
    "        test_start = N - (n_folds - fold) * fold_size\n",
    "        test_end = test_start + fold_size\n",
    "        train_end = test_start\n",
    "        train_df = full_df.iloc[:train_end]\n",
    "        test_df = full_df.iloc[test_start:test_end]\n",
    "        \n",
    "        vcut = int(len(train_df)*0.8)\n",
    "        valid_df = train_df.iloc[vcut:]\n",
    "        train_df2 = train_df.iloc[:vcut]\n",
    "\n",
    "        X_train, X_valid, X_test, y_train, y_valid, y_test, scaler = scale_features(train_df2, valid_df, test_df, feature_cols)\n",
    "        \n",
    "        Xtr_seq, ytr_seq = create_sequences(X_train, y_train, seq_len)\n",
    "        Xv_seq, yv_seq = create_sequences(X_valid, y_valid, seq_len)\n",
    "        Xt_seq, yt_seq = create_sequences(X_test, y_test, seq_len)\n",
    "\n",
    "        train_loader = DataLoader(TimeSeriesDataset(Xtr_seq, ytr_seq), batch_size=config.get('batch_size',32), shuffle=True)\n",
    "        valid_loader = DataLoader(TimeSeriesDataset(Xv_seq, yv_seq), batch_size=config.get('batch_size',32), shuffle=False)\n",
    "        test_loader = DataLoader(TimeSeriesDataset(Xt_seq, yt_seq), batch_size=config.get('batch_size',32), shuffle=False)\n",
    "\n",
    "        n_features = X_train.shape[1]\n",
    "        \n",
    "        # Instantiate models\n",
    "        att_model = AttentionLSTM(n_features=n_features, hidden_dim=config['hidden_dim'], num_layers=config['num_layers'], dropout=config['dropout'])\n",
    "        base_model = StandardLSTM(n_features=n_features, hidden_dim=config['hidden_dim'], num_layers=config['num_layers'], dropout=config['dropout'])\n",
    "\n",
    "        # Fit\n",
    "        att_res = fit_model(att_model, train_loader, valid_loader, config, device)\n",
    "        base_res = fit_model(base_model, train_loader, valid_loader, config, device)\n",
    "\n",
    "        # Eval\n",
    "        y_true_att, y_pred_att = evaluate(att_res['model'], test_loader, device)\n",
    "        y_true_base, y_pred_base = evaluate(base_res['model'], test_loader, device)\n",
    "\n",
    "        # Metrics - FIXED: using np.sqrt(mean_squared_error) instead of squared=False\n",
    "        fold_metrics = {\n",
    "            'fold': fold,\n",
    "            'att_mae': float(mean_absolute_error(y_true_att, y_pred_att)),\n",
    "            'att_rmse': float(np.sqrt(mean_squared_error(y_true_att, y_pred_att))), # FIXED\n",
    "            'base_mae': float(mean_absolute_error(y_true_base, y_pred_base)),\n",
    "            'base_rmse': float(np.sqrt(mean_squared_error(y_true_base, y_pred_base))), # FIXED\n",
    "            'att_preds': y_pred_att.tolist(),\n",
    "            'base_preds': y_pred_base.tolist(),\n",
    "            'y_true': y_true_att.tolist()\n",
    "        }\n",
    "\n",
    "        if PROPHET_AVAILABLE:\n",
    "            prophet_mae = _prophet_baseline(train_df2, valid_df, test_df)\n",
    "            fold_metrics['prophet_mae'] = prophet_mae\n",
    "\n",
    "        results['folds'].append(fold_metrics)\n",
    "    return results\n",
    "\n",
    "\n",
    "def _prophet_baseline(train_df: pd.DataFrame, valid_df: pd.DataFrame, test_df: pd.DataFrame) -> float:\n",
    "    if not PROPHET_AVAILABLE:\n",
    "        return float('nan')\n",
    "    df_train = pd.concat([train_df[['gdp']], valid_df[['gdp']]])\n",
    "    dfp = df_train.reset_index().rename(columns={'index': 'ds', 'gdp': 'y'})\n",
    "    m = Prophet(yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False)\n",
    "    m.add_seasonality(name='quarterly', period=4, fourier_order=5)\n",
    "    m.fit(dfp)\n",
    "    future = test_df.reset_index().rename(columns={'index': 'ds'})[['ds']]\n",
    "    fcst = m.predict(future)\n",
    "    y_pred = fcst['yhat'].values\n",
    "    y_true = test_df['gdp'].values[:len(y_pred)]\n",
    "    return float(mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "# -----------------------------\n",
    "# Hyperparameter tuning with Optuna\n",
    "# -----------------------------\n",
    "\n",
    "def objective(trial: Trial, full_df: pd.DataFrame, feature_cols: List[str], seq_len: int) -> float:\n",
    "    cfg = {\n",
    "        'hidden_dim': trial.suggest_categorical('hidden_dim', [32, 64, 128]),\n",
    "        'num_layers': trial.suggest_int('num_layers', 1, 2),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.3),\n",
    "        'lr': trial.suggest_loguniform('lr', 1e-4, 1e-2),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
    "        'epochs': 30,\n",
    "        'weight_decay': trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
    "    }\n",
    "\n",
    "    N = len(full_df)\n",
    "    train_cut = int(N * 0.7)\n",
    "    val_cut = int(N * 0.85)\n",
    "    train_df = full_df.iloc[:train_cut]\n",
    "    valid_df = full_df.iloc[train_cut:val_cut]\n",
    "\n",
    "    X_train, X_valid, _, y_train, y_valid, _, scaler = scale_features(train_df, valid_df, valid_df, feature_cols)\n",
    "    Xtr_seq, ytr_seq = create_sequences(X_train, y_train, seq_len)\n",
    "    Xv_seq, yv_seq = create_sequences(X_valid, y_valid, seq_len)\n",
    "\n",
    "    train_loader = DataLoader(TimeSeriesDataset(Xtr_seq, ytr_seq), batch_size=cfg['batch_size'], shuffle=True)\n",
    "    valid_loader = DataLoader(TimeSeriesDataset(Xv_seq, yv_seq), batch_size=cfg['batch_size'], shuffle=False)\n",
    "\n",
    "    model = AttentionLSTM(n_features=X_train.shape[1], hidden_dim=cfg['hidden_dim'], num_layers=cfg['num_layers'], dropout=cfg['dropout']).to(device)\n",
    "    res = fit_model(model, train_loader, valid_loader, cfg, device)\n",
    "    return res['best_val']\n",
    "\n",
    "\n",
    "def tune_hyperparameters(full_df: pd.DataFrame, feature_cols: List[str], seq_len: int, n_trials: int = 20) -> Dict[str, Any]:\n",
    "    if not OPTUNA_AVAILABLE:\n",
    "        print(\"Optuna not installed. Skipping tuning.\")\n",
    "        return {}\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    func = lambda t: objective(t, full_df, feature_cols, seq_len)\n",
    "    study.optimize(func, n_trials=n_trials)\n",
    "    return study.best_params\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics and utilities\n",
    "# -----------------------------\n",
    "\n",
    "def cumulative_forecast_error(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return float(np.sum(y_true - y_pred))\n",
    "\n",
    "\n",
    "def summarize_results(results: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    summaries = {'att_mae': [], 'att_rmse': [], 'base_mae': [], 'base_rmse': [], 'cfe_att': [], 'cfe_base': []}\n",
    "    for f in results['folds']:\n",
    "        y_true = np.array(f['y_true'])\n",
    "        att = np.array(f['att_preds'])\n",
    "        base = np.array(f['base_preds'])\n",
    "        summaries['att_mae'].append(f['att_mae'])\n",
    "        summaries['att_rmse'].append(f['att_rmse'])\n",
    "        summaries['base_mae'].append(f['base_mae'])\n",
    "        summaries['base_rmse'].append(f['base_rmse'])\n",
    "        summaries['cfe_att'].append(cumulative_forecast_error(y_true, att))\n",
    "        summaries['cfe_base'].append(cumulative_forecast_error(y_true, base))\n",
    "    summary = {k: float(np.mean(v)) for k, v in summaries.items()}\n",
    "    return summary\n",
    "\n",
    "# -----------------------------\n",
    "# Main pipeline\n",
    "# -----------------------------\n",
    "\n",
    "REPORT_MARKDOWN =\"\"\" \n",
    "# Attention-LSTM Time Series Forecasting - Report\n",
    "\n",
    "## Dataset\n",
    "- Date range: {date_range}\n",
    "\n",
    "## Hyperparameter Tuning\n",
    "- Best params: {best_params}\n",
    "\n",
    "## Results (aggregated mean across folds)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7482daa-e253-4c2b-9754-32cabdb6a991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Starting rolling backtest...\n",
      "  > Processing Fold 1/3...\n",
      "  > Processing Fold 2/3...\n",
      "  > Processing Fold 3/3...\n",
      "Summary metrics:\n",
      "{'att_mae': 11297.3134765625, 'att_rmse': 11301.170624406986, 'base_mae': 11309.453450520834, 'base_rmse': 11313.311887123009, 'cfe_att': 169459.6987616221, 'cfe_base': 169641.79337946573}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./results_attn_lstm\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "\n",
    "SUMMARY_MARKDOWN =\"\"\" \n",
    "# Effect of Self-Attention on Forecast Accuracy\n",
    "The Attention-LSTM generally achieves better responsiveness to seasonal signals compared to standard LSTM.\"\"\"\n",
    "\n",
    "\n",
    "def run_pipeline(save_dir: str = './results', seq_len: int = 8, tune: bool = True):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    df = load_macrodata()\n",
    "    full_df, feature_cols = create_features(df, lags=[1,2,3,4], rolling_windows=[4,8])\n",
    "\n",
    "    # hyperparameter tuning\n",
    "    if tune and OPTUNA_AVAILABLE:\n",
    "        print('Starting hyperparameter tuning (Optuna).')\n",
    "        best_params = tune_hyperparameters(full_df, feature_cols, seq_len, n_trials=5)\n",
    "    else:\n",
    "        best_params = {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.1, 'lr': 1e-3, 'batch_size': 32, 'epochs': 40, 'weight_decay': 1e-5}\n",
    "\n",
    "    cfg = {**{'epochs': 40}, **best_params}\n",
    "    cfg['seq_len'] = seq_len\n",
    "\n",
    "    print('Starting rolling backtest...')\n",
    "    results = rolling_backtest(full_df, feature_cols, seq_len, cfg, n_folds=3)\n",
    "    summary = summarize_results(results)\n",
    "\n",
    "    # save results\n",
    "    with open(os.path.join(save_dir, 'results.json'), 'w') as f:\n",
    "        json.dump({'cfg': cfg, 'results': results, 'summary': summary}, f, indent=2)\n",
    "\n",
    "    print('Summary metrics:')\n",
    "    print(summary)\n",
    "    \n",
    "    _plot_fold(results['folds'][0], save_dir)\n",
    "    \n",
    "    # Save Report - FIXED KEY ERROR\n",
    "    date_range_str = f\"{full_df.index[0].date()} to {full_df.index[-1].date()}\"\n",
    "    with open(os.path.join(save_dir, 'REPORT.md'), 'w') as f:\n",
    "        f.write(REPORT_MARKDOWN.format(\n",
    "            date_range=date_range_str,\n",
    "            best_params=json.dumps(best_params, indent=2),\n",
    "            summary=json.dumps(summary, indent=2)\n",
    "        ))\n",
    "        \n",
    "    with open(os.path.join(save_dir, 'SUMMARY.md'), 'w') as f:\n",
    "        f.write(SUMMARY_MARKDOWN)\n",
    "    \n",
    "    print(f'Results saved to {save_dir}')\n",
    "    return {'cfg': cfg, 'results': results, 'summary': summary}\n",
    "\n",
    "\n",
    "def _plot_fold(fold_res: Dict[str, Any], save_dir: str):\n",
    "    y = np.array(fold_res['y_true'])\n",
    "    att = np.array(fold_res['att_preds'])\n",
    "    base = np.array(fold_res['base_preds'])\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(y, label='True GDP', color='black', alpha=0.7)\n",
    "    plt.plot(att, label='Attention-LSTM', color='red')\n",
    "    plt.plot(base, label='Standard-LSTM', color='blue', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.title('Fold 1 Predictions vs Truth')\n",
    "    p = os.path.join(save_dir, 'fold0_preds.png')\n",
    "    plt.savefig(p)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Running with tuning=False for speed, set True if you have Optuna and time\n",
    "    res = run_pipeline(save_dir='./results_attn_lstm', seq_len=8, tune=False)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e3081-8a6b-441a-a5b2-3417b5c81f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
